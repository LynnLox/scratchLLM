{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ffd51a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#switch to parallel processing \n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#print(device)\n",
    "#Ingrated GPU: force PyTorch to use the CPU for computations, which is the appropriate choice for systems without a dedicated GPU.\n",
    "#it should run without trying to access CUDA resources.\n",
    "device ='cuda'if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "block_size = 8\n",
    "batch_size = 4 #No of blocks in parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35bf92fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232272\n",
      "ï»¿DOROTHY AND THE WIZARD IN OZ\n",
      "\n",
      "BY\n",
      "\n",
      "L. FRANK BAUM\n",
      "\n",
      "AUTHOR OF THE WIZARD OF OZ, THE LAND OF OZ, OZMA OF OZ, ETC.\n",
      "\n",
      "ILLUSTRATED BY JOHN R. NEILL\n",
      "\n",
      "BOOKS OF WONDER WILLIAM MORROW & CO., INC. NEW YORK\n",
      "\n",
      "\n",
      "[Ill\n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt', 'r',encoding ='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(len(text))\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a081b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54cc5aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 58, 65, 65, 68]\n",
      "hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([80, 28, 39,  ...,  0,  0,  0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\\\n",
    "\n",
    "print(encode(\"hello\"))\n",
    "encoded_hello=encode(\"hello\")\n",
    "decoded_hello=decode(encoded_hello)\n",
    "print(decoded_hello)\n",
    "\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e913fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,  1, 47,\n",
      "        33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0, 26, 49,  0,  0, 36,\n",
      "        11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,  0,  0, 25, 45, 44, 32,\n",
      "        39, 42,  1, 39, 30,  1, 44, 32, 29,  1, 47, 33, 50, 25, 42, 28,  1, 39,\n",
      "        30,  1, 39, 50,  9,  1, 44, 32, 29,  1, 36, 25, 38, 28,  1, 39, 30,  1,\n",
      "        39, 50,  9,  1, 39, 50, 37, 25,  1, 39])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60093d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c410d5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([80]) target is tensor(28)\n",
      "When input is tensor([80, 28]) target is tensor(39)\n",
      "When input is tensor([80, 28, 39]) target is tensor(42)\n",
      "When input is tensor([80, 28, 39, 42]) target is tensor(39)\n",
      "When input is tensor([80, 28, 39, 42, 39]) target is tensor(44)\n",
      "When input is tensor([80, 28, 39, 42, 39, 44]) target is tensor(32)\n",
      "When input is tensor([80, 28, 39, 42, 39, 44, 32]) target is tensor(49)\n",
      "When input is tensor([80, 28, 39, 42, 39, 44, 32, 49]) target is tensor(1)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(\"When input is\", context, \"target is\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b0a690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[78, 68, 74,  1, 76, 71, 68, 67],\n",
      "        [ 1, 54, 73,  1, 54,  1, 75, 58],\n",
      "        [33, 43,  1, 42, 39, 39, 37, 24],\n",
      "        [68, 57, 62, 58, 72,  1, 68, 59]])\n",
      "targets:\n",
      "tensor([[68, 74,  1, 76, 71, 68, 67, 60],\n",
      "        [54, 73,  1, 54,  1, 75, 58, 67],\n",
      "        [43,  1, 42, 39, 39, 37, 24,  3],\n",
      "        [57, 62, 58, 72,  1, 68, 59,  1]])\n"
     ]
    }
   ],
   "source": [
    " n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "# print(x.shape)\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super.__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size.vocab_size)\n",
    "        #matrice x and y represent vocab size\n",
    "        \n",
    "    def forward_pass( )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
